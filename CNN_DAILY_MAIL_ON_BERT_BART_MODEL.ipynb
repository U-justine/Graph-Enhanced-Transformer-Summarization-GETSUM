{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxQzub6_N67p"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers sentence-transformers evaluate bert-score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    BartTokenizer,\n",
        "    BartForConditionalGeneration,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "nltk.download(\"punkt\")\n"
      ],
      "metadata": {
        "id": "MkXr2LVsOMT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "print(dataset)\n",
        "\n",
        "train_size = len(dataset[\"train\"])\n",
        "val_size = len(dataset[\"validation\"])\n",
        "test_size = len(dataset[\"test\"])\n",
        "\n",
        "print(\"Train:\", train_size, \"Val:\", val_size, \"Test:\", test_size)\n"
      ],
      "metadata": {
        "id": "bcAhRMxxOMNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT sentence embeddings\n",
        "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def extractive_stage(article, top_k=5):\n",
        "    sentences = sent_tokenize(article)\n",
        "    if len(sentences) <= top_k:\n",
        "        return article\n",
        "    embeddings = bert_model.encode(sentences, convert_to_tensor=True)\n",
        "    doc_embedding = torch.mean(embeddings, dim=0, keepdim=True)\n",
        "    scores = util.cos_sim(doc_embedding, embeddings)[0]\n",
        "    top_indices = torch.topk(scores, k=top_k).indices\n",
        "    selected_sentences = [sentences[i] for i in top_indices]\n",
        "    return \" \".join(selected_sentences)\n"
      ],
      "metadata": {
        "id": "csFCfZJAOMF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch-wise extractive preprocessing â†’ save results\n",
        "# This is the new Cell 4\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 500\n",
        "top_k = 5\n",
        "\n",
        "def process_and_save(split, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i in tqdm(range(0, len(split), batch_size)):\n",
        "            batch = split[i:i+batch_size]\n",
        "            for example in batch:\n",
        "                reduced_article = extractive_stage(example[\"article\"], top_k=top_k)\n",
        "                json_line = json.dumps({\n",
        "                    \"article\": reduced_article,\n",
        "                    \"highlights\": example[\"highlights\"]\n",
        "                })\n",
        "                f.write(json_line + \"\\n\")\n",
        "\n",
        "# Run for all splits\n",
        "process_and_save(dataset[\"train\"], \"train_extractive.jsonl\")\n",
        "process_and_save(dataset[\"validation\"], \"val_extractive.jsonl\")\n",
        "process_and_save(dataset[\"test\"], \"test_extractive.jsonl\")"
      ],
      "metadata": {
        "id": "_kdWj_rNOL95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BART tokenizer & model\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "max_input_length = 1024\n",
        "max_target_length = 256\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    inputs = tokenizer(batch[\"article\"], max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(batch[\"highlights\"], max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "train_tokenized = tokenize_batch(train_processed)\n",
        "val_tokenized = tokenize_batch(val_processed)\n",
        "test_tokenized = tokenize_batch(test_processed)\n"
      ],
      "metadata": {
        "id": "r39gE8QmOZiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_tokenized)\n",
        "val_dataset = Dataset.from_dict(val_tokenized)\n",
        "test_dataset = Dataset.from_dict(test_tokenized)\n"
      ],
      "metadata": {
        "id": "7pO2Hb6KOcKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4  # increase if GPU memory allows\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./hybrid_bert_bart\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=1,   # increase to 3-5 if compute allows\n",
        "    predict_with_generate=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "vH7c7dy8PPVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    bertscore_result = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_result[\"rouge1\"],\n",
        "        \"rouge2\": rouge_result[\"rouge2\"],\n",
        "        \"rougeL\": rouge_result[\"rougeL\"],\n",
        "        \"bertscore_f1\": np.mean(bertscore_result[\"f1\"])\n",
        "    }\n"
      ],
      "metadata": {
        "id": "gJZFwcc6PSg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "oAtFE6ViPWOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(test_results)"
      ],
      "metadata": {
        "id": "DKyYxw0XPXDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}