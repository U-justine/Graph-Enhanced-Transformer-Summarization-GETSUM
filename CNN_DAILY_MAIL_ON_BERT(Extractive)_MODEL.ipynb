{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5HWfUSnr4ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 1 - Imports\n",
        "import numpy as np\n",
        "import torch\n",
        "import nltk\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "from evaluate import load\n",
        "import json\n",
        "\n",
        "nltk.download(\"punkt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iWrwrZrVtbFe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 287113\n",
            "Validation size: 13368\n",
            "Test size: 11490\n"
          ]
        }
      ],
      "source": [
        "# Cell 2 - Load full CNN/DailyMail\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"default\")\n",
        "\n",
        "print(\"Train size:\", len(dataset[\"train\"]))\n",
        "print(\"Validation size:\", len(dataset[\"validation\"]))\n",
        "print(\"Test size:\", len(dataset[\"test\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bTyFN-Z7taX9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61d95858bd7a43dc9a2389fdce910308",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53da44b5e838460b8c97706303a32a69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa2bc6384d374f9296c248b187763f50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 3 - Load BERT\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wr7VNhhithYJ"
      },
      "outputs": [],
      "source": [
        "# Cell 4 - Sentence embeddings using BERT\n",
        "def get_sentence_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Mean pooling\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tTyEl4ActqlT"
      },
      "outputs": [],
      "source": [
        "# Cell 4 - Sentence embeddings using BERT\n",
        "def get_sentence_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Mean pooling\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "evYH33ILtu3e"
      },
      "outputs": [],
      "source": [
        "# Cell 5 - Summarization with BERT + TextRank\n",
        "def bert_extractive_summarize(article, num_sentences=3):\n",
        "    sentences = nltk.sent_tokenize(article)\n",
        "    if len(sentences) <= num_sentences:\n",
        "        return article\n",
        "\n",
        "    # Get embeddings for each sentence\n",
        "    embeddings = [get_sentence_embedding(sent) for sent in sentences]\n",
        "\n",
        "    # Similarity matrix\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "    # Graph\n",
        "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "    summary = \" \".join([s for _, s in ranked_sentences[:num_sentences]])\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v4VHChxt6kq"
      },
      "outputs": [],
      "source": [
        "# Cell 6 - Process full splits and save results\n",
        "def process_split(split, output_file, n_sentences=3):\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for example in split:\n",
        "            article = example[\"article\"]\n",
        "            ref_summary = example[\"highlights\"]\n",
        "            pred_summary = bert_extractive_summarize(article, n_sentences)\n",
        "            f.write(json.dumps({\n",
        "                \"ref_summary\": ref_summary,\n",
        "                \"pred_summary\": pred_summary\n",
        "            }) + \"\\n\")\n",
        "\n",
        "# Run on all splits\n",
        "process_split(dataset[\"validation\"], \"bert_val.jsonl\", n_sentences=3)\n",
        "process_split(dataset[\"test\"], \"bert_test.jsonl\", n_sentences=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOzrzp__t-1i"
      },
      "outputs": [],
      "source": [
        "# Cell 7 - Evaluate with ROUGE + BERTScore\n",
        "rouge = load(\"rouge\")\n",
        "bertscore = load(\"bertscore\")\n",
        "\n",
        "def evaluate(file_path):\n",
        "    preds, refs = [], []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            preds.append(data[\"pred_summary\"])\n",
        "            refs.append(data[\"ref_summary\"])\n",
        "\n",
        "    rouge_result = rouge.compute(predictions=preds, references=refs)\n",
        "    bertscore_result = bertscore.compute(predictions=preds, references=refs, lang=\"en\")\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_result[\"rouge1\"],\n",
        "        \"rouge2\": rouge_result[\"rouge2\"],\n",
        "        \"rougeL\": rouge_result[\"rougeL\"],\n",
        "        \"bertscore_f1\": np.mean(bertscore_result[\"f1\"])\n",
        "    }\n",
        "\n",
        "print(\"Validation:\", evaluate(\"bert_val.jsonl\"))\n",
        "print(\"Test:\", evaluate(\"bert_test.jsonl\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
